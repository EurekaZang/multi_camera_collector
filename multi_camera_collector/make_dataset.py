#!/usr/bin/env python3
"""
å¤šç›¸æœºæ•°æ®é›†ä¸€é”®åˆ¶ä½œå·¥å…·

è¿™æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºä¸ºmulti_camera_collectorèŠ‚ç‚¹é‡‡é›†çš„æ•°æ®é›†
ç”Ÿæˆä¾¿äºæ·±åº¦å­¦ä¹ ä½¿ç”¨çš„CSVç´¢å¼•æ–‡ä»¶ã€‚
"""

import os
import sys
import argparse
from pathlib import Path

# å°è¯•å¤šç§å¯¼å…¥æ–¹å¼ä»¥æ”¯æŒä¸åŒçš„æ‰§è¡Œç¯å¢ƒ
try:
    # æ–¹å¼1: ä½œä¸ºROS2åŒ…å¯¼å…¥ï¼ˆæ¨èï¼‰
    from multi_camera_collector.dataset_generator import DatasetGenerator
except ImportError:
    try:
        # æ–¹å¼2: ä»å½“å‰ç›®å½•å¯¼å…¥ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        current_dir = Path(__file__).parent
        if str(current_dir) not in sys.path:
            sys.path.insert(0, str(current_dir))
        from dataset_generator import DatasetGenerator
    except ImportError:
        print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥dataset_generatoræ¨¡å—")
        print("è¯·ç¡®ä¿ï¼š")
        print("  1. ROS2åŒ…å·²æ­£ç¡®å®‰è£… (colcon build)")
        print("  2. æˆ–è€…æ­¤è„šæœ¬ä¸dataset_generator.pyåœ¨åŒä¸€ç›®å½•ä¸­")
        sys.exit(1)


def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    print("ğŸ¤– å¤šç›¸æœºæ•°æ®é›†ä¸€é”®åˆ¶ä½œå·¥å…·")
    print("=" * 50)
    
    parser = argparse.ArgumentParser(
        description='ä¸ºmulti_camera_collectoræ•°æ®é›†ç”ŸæˆCSVç´¢å¼•æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ç”Ÿæˆç»„åˆCSVæ–‡ä»¶ï¼ˆæ¨èç”¨äºæ·±åº¦å­¦ä¹ ï¼‰
  ./make_dataset.py /path/to/dataset
  
  # ä¸ºæ¯ä¸ªç›¸æœºç”Ÿæˆå•ç‹¬çš„CSVæ–‡ä»¶
  ./make_dataset.py /path/to/dataset --format separate
  
  # åŒæ—¶ç”Ÿæˆç»„åˆå’Œå•ç‹¬çš„CSVæ–‡ä»¶
  ./make_dataset.py /path/to/dataset --format both

æ•°æ®é›†ç›®å½•ç»“æ„åº”ä¸º:
  dataset/
  â”œâ”€â”€ camera/
  â”‚   â”œâ”€â”€ rgb/           # æ ‡å‡†ç›¸æœºRGBå›¾åƒ
  â”‚   â”œâ”€â”€ depth/         # æ ‡å‡†ç›¸æœºæ·±åº¦å›¾åƒ
  â”‚   â””â”€â”€ camera_info/   # æ ‡å‡†ç›¸æœºå‚æ•°æ–‡ä»¶
  â””â”€â”€ camera_femto/
      â”œâ”€â”€ rgb/           # Femtoç›¸æœºRGBå›¾åƒ
      â”œâ”€â”€ depth/         # Femtoç›¸æœºæ·±åº¦å›¾åƒ
      â””â”€â”€ camera_info/   # Femtoç›¸æœºå‚æ•°æ–‡ä»¶

ç”Ÿæˆçš„CSVæ–‡ä»¶å¯ç›´æ¥ç”¨äº:
  - PyTorch Datasetç±»
  - TensorFlow data pipeline
  - æ·±åº¦å­¦ä¹ è®­ç»ƒè„šæœ¬
  - æ•°æ®åˆ†æå’Œå¯è§†åŒ–
        """
    )
    
    parser.add_argument(
        'dataset_path',
        help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ï¼ˆåŒ…å«cameraå’Œcamera_femtoå­ç›®å½•ï¼‰'
    )
    
    parser.add_argument(
        '--format', '-f',
        choices=['combined', 'separate', 'both'],
        default='combined',
        help='CSVæ–‡ä»¶è¾“å‡ºæ ¼å¼:\n'
             '  combined: å•ä¸ªCSVåŒ…å«æ‰€æœ‰ç›¸æœºæ•°æ®ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰\n'
             '  separate: æ¯ä¸ªç›¸æœºå•ç‹¬çš„CSVæ–‡ä»¶\n'
             '  both: åŒæ—¶ç”Ÿæˆç»„åˆå’Œå•ç‹¬çš„CSVæ–‡ä»¶'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯æ•°æ®é›†è·¯å¾„
    dataset_path = Path(args.dataset_path).resolve()
    if not dataset_path.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        sys.exit(1)
    
    if not dataset_path.is_dir():
        print(f"âŒ é”™è¯¯: æŒ‡å®šè·¯å¾„ä¸æ˜¯ç›®å½•: {dataset_path}")
        sys.exit(1)
    
    print(f"ğŸ“‚ æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"ğŸ“Š è¾“å‡ºæ ¼å¼: {args.format}")
    print()
    
    try:
        # åˆ›å»ºæ•°æ®é›†ç”Ÿæˆå™¨
        if args.verbose:
            print("ğŸ”§ åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨...")
        
        generator = DatasetGenerator(str(dataset_path))
        
        # ç”ŸæˆCSVæ–‡ä»¶
        if args.verbose:
            print("ğŸš€ å¼€å§‹ç”ŸæˆCSVæ–‡ä»¶...")
        
        generated_files = generator.generate_csv_files(args.format)
        
        if generated_files:
            print("\nğŸ‰ æ•°æ®é›†åˆ¶ä½œå®Œæˆï¼")
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶:")
            for file_path in generated_files:
                file_size = Path(file_path).stat().st_size
                print(f"  ğŸ“„ {Path(file_path).name} ({file_size:,} bytes)")
            
            print(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
            print(f"  â€¢ CSVæ–‡ä»¶è·¯å¾„å‡ä¸ºç›¸å¯¹äºæ•°æ®é›†æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„")
            print(f"  â€¢ å¯ç›´æ¥åœ¨æ·±åº¦å­¦ä¹ ä»£ç ä¸­ä½¿ç”¨è¿™äº›CSVæ–‡ä»¶ä½œä¸ºæ•°æ®ç´¢å¼•")
            print(f"  â€¢ æ¨èä½¿ç”¨ dataset.csvï¼ˆç»„åˆæ–‡ä»¶ï¼‰è¿›è¡Œè®­ç»ƒ")
            print(f"  â€¢ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ° dataset_statistics.json")
            
        else:
            print("\nâŒ æ•°æ®é›†åˆ¶ä½œå¤±è´¥")
            print("å¯èƒ½çš„åŸå› :")
            print("  â€¢ æ•°æ®é›†ç›®å½•ç»“æ„ä¸æ­£ç¡®")
            print("  â€¢ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒæ•°æ®")
            print("  â€¢ ç¼ºå°‘å¿…è¦çš„camera_infoæ–‡ä»¶")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        if args.verbose:
            import traceback
            print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()