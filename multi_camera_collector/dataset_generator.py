#!/usr/bin/env python3
"""
å¤šç›¸æœºæ•°æ®é›†CSVç”Ÿæˆå™¨

æ­¤æ¨¡å—è´Ÿè´£æ‰«æç”±data_collectorèŠ‚ç‚¹ç”Ÿæˆçš„æ•°æ®é›†ç›®å½•ï¼Œ
å¹¶ç”Ÿæˆä¾¿äºæ·±åº¦å­¦ä¹ ä½¿ç”¨çš„CSVç´¢å¼•æ–‡ä»¶ã€‚
"""

import os
import glob
import pandas as pd
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import argparse
import sys


class DatasetGenerator:
    """æ•°æ®é›†CSVæ–‡ä»¶ç”Ÿæˆå™¨"""
    
    def __init__(self, dataset_path: str):
        """
        åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨
        
        Args:
            dataset_path (str): æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„
        """
        self.dataset_path = Path(dataset_path).resolve()
        self.camera_types = ['camera', 'camera_femto']
        
        # éªŒè¯æ•°æ®é›†è·¯å¾„
        if not self.dataset_path.exists():
            raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {self.dataset_path}")
        
        print(f"åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨ï¼Œæ•°æ®é›†è·¯å¾„: {self.dataset_path}")
    
    def _validate_dataset_structure(self) -> Dict[str, bool]:
        """
        éªŒè¯æ•°æ®é›†ç›®å½•ç»“æ„æ˜¯å¦å®Œæ•´
        
        Returns:
            Dict[str, bool]: æ¯ä¸ªç›¸æœºç±»å‹çš„éªŒè¯ç»“æœ
        """
        validation_results = {}
        
        for camera_type in self.camera_types:
            camera_path = self.dataset_path / camera_type
            
            # æ£€æŸ¥å¿…è¦çš„å­ç›®å½•
            required_dirs = ['rgb', 'depth', 'camera_info']
            dirs_exist = all((camera_path / sub_dir).exists() for sub_dir in required_dirs)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®æ–‡ä»¶
            has_data = any(
                len(list((camera_path / sub_dir).glob('*.png'))) > 0 
                for sub_dir in ['rgb', 'depth']
            )
            
            validation_results[camera_type] = dirs_exist and has_data
            
            status = "âœ“" if validation_results[camera_type] else "âœ—"
            print(f"{status} {camera_type}: ç›®å½•ç»“æ„{'å®Œæ•´' if dirs_exist else 'ä¸å®Œæ•´'}ï¼Œ"
                  f"{'æœ‰æ•°æ®' if has_data else 'æ— æ•°æ®'}")
        
        return validation_results
    
    def _extract_timestamp_from_filename(self, filename: str) -> Optional[int]:
        """
        ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
        
        Args:
            filename (str): æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
            
        Returns:
            Optional[int]: æ—¶é—´æˆ³ï¼ˆçº³ç§’ï¼‰ï¼Œå¦‚æœæå–å¤±è´¥è¿”å›None
        """
        try:
            # ç§»é™¤æ–‡ä»¶æ‰©å±•åå’Œå¯èƒ½çš„åç¼€
            name_without_ext = filename.split('.')[0]
            
            # å¤„ç†camera_infoæ–‡ä»¶çš„ç‰¹æ®Šå‘½åæ ¼å¼
            if '_rgb_camera_info' in name_without_ext:
                timestamp_str = name_without_ext.replace('_rgb_camera_info', '')
            elif '_depth_camera_info' in name_without_ext:
                timestamp_str = name_without_ext.replace('_depth_camera_info', '')
            else:
                timestamp_str = name_without_ext
            
            return int(timestamp_str)
        except ValueError:
            return None
    
    def _get_image_pairs_for_camera(self, camera_type: str) -> List[Dict]:
        """
        è·å–æŒ‡å®šç›¸æœºçš„æ‰€æœ‰å›¾åƒå¯¹ä¿¡æ¯
        
        Args:
            camera_type (str): ç›¸æœºç±»å‹ ('camera' æˆ– 'camera_femto')
            
        Returns:
            List[Dict]: å›¾åƒå¯¹ä¿¡æ¯åˆ—è¡¨
        """
        camera_path = self.dataset_path / camera_type
        rgb_path = camera_path / 'rgb'
        depth_path = camera_path / 'depth'
        camera_info_path = camera_path / 'camera_info'
        
        # è·å–æ‰€æœ‰RGBå›¾åƒæ–‡ä»¶
        rgb_files = list(rgb_path.glob('*.png'))
        rgb_timestamps = set()
        
        for rgb_file in rgb_files:
            timestamp = self._extract_timestamp_from_filename(rgb_file.name)
            if timestamp is not None:
                rgb_timestamps.add(timestamp)
        
        # æ„å»ºå›¾åƒå¯¹åˆ—è¡¨
        image_pairs = []
        
        for timestamp in sorted(rgb_timestamps):
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            rgb_file = rgb_path / f"{timestamp}.png"
            depth_file = depth_path / f"{timestamp}.png"
            rgb_info_file = camera_info_path / f"{timestamp}_rgb_camera_info.json"
            depth_info_file = camera_info_path / f"{timestamp}_depth_camera_info.json"
            
            # æ£€æŸ¥æ‰€æœ‰å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if all(f.exists() for f in [rgb_file, depth_file, rgb_info_file, depth_info_file]):
                # è®¡ç®—ç›¸å¯¹äºæ•°æ®é›†æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
                pair_info = {
                    'camera_type': camera_type,
                    'timestamp': timestamp,
                    'rgb_path': os.path.relpath(rgb_file, self.dataset_path),
                    'depth_path': os.path.relpath(depth_file, self.dataset_path),
                    'rgb_camera_info_path': os.path.relpath(rgb_info_file, self.dataset_path),
                    'depth_camera_info_path': os.path.relpath(depth_info_file, self.dataset_path),
                    'rgb_absolute_path': str(rgb_file),
                    'depth_absolute_path': str(depth_file),
                    'rgb_camera_info_absolute_path': str(rgb_info_file),
                    'depth_camera_info_absolute_path': str(depth_info_file),
                }
                
                # å°è¯•è¯»å–camera_infoè·å–å›¾åƒå°ºå¯¸ä¿¡æ¯
                try:
                    with open(rgb_info_file, 'r') as f:
                        rgb_info = json.load(f)
                        pair_info['rgb_width'] = rgb_info['width']
                        pair_info['rgb_height'] = rgb_info['height']
                except:
                    pair_info['rgb_width'] = None
                    pair_info['rgb_height'] = None
                
                try:
                    with open(depth_info_file, 'r') as f:
                        depth_info = json.load(f)
                        pair_info['depth_width'] = depth_info['width']
                        pair_info['depth_height'] = depth_info['height']
                except:
                    pair_info['depth_width'] = None
                    pair_info['depth_height'] = None
                
                image_pairs.append(pair_info)
        
        return image_pairs
    
    def generate_csv_files(self, output_format: str = 'combined') -> List[str]:
        """
        ç”ŸæˆCSVç´¢å¼•æ–‡ä»¶
        
        Args:
            output_format (str): è¾“å‡ºæ ¼å¼
                - 'combined': ç”Ÿæˆå•ä¸ªåŒ…å«æ‰€æœ‰ç›¸æœºæ•°æ®çš„CSVæ–‡ä»¶
                - 'separate': ä¸ºæ¯ä¸ªç›¸æœºç”Ÿæˆå•ç‹¬çš„CSVæ–‡ä»¶
                - 'both': åŒæ—¶ç”Ÿæˆç»„åˆå’Œå•ç‹¬çš„CSVæ–‡ä»¶
                
        Returns:
            List[str]: ç”Ÿæˆçš„CSVæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # éªŒè¯æ•°æ®é›†ç»“æ„
        validation_results = self._validate_dataset_structure()
        
        valid_cameras = [camera for camera, valid in validation_results.items() if valid]
        
        if not valid_cameras:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç›¸æœºæ•°æ®ï¼Œæ— æ³•ç”ŸæˆCSVæ–‡ä»¶")
            return []
        
        print(f"\nğŸ“Š å¼€å§‹ç”ŸæˆCSVæ–‡ä»¶ï¼Œæœ‰æ•ˆç›¸æœº: {valid_cameras}")
        
        generated_files = []
        all_pairs = []
        
        # æ”¶é›†æ‰€æœ‰ç›¸æœºçš„æ•°æ®
        for camera_type in valid_cameras:
            print(f"ğŸ” æ‰«æ {camera_type} æ•°æ®...")
            pairs = self._get_image_pairs_for_camera(camera_type)
            all_pairs.extend(pairs)
            print(f"âœ“ {camera_type}: æ‰¾åˆ° {len(pairs)} ç»„å›¾åƒå¯¹")
            
            # å¦‚æœéœ€è¦ç”Ÿæˆå•ç‹¬çš„CSVæ–‡ä»¶
            if output_format in ['separate', 'both']:
                df_single = pd.DataFrame(pairs)
                if not df_single.empty:
                    single_csv_path = self.dataset_path / f"{camera_type}_dataset.csv"
                    df_single.to_csv(single_csv_path, index=False)
                    generated_files.append(str(single_csv_path))
                    print(f"âœ“ å·²ç”Ÿæˆ {camera_type} CSVæ–‡ä»¶: {single_csv_path}")
        
        # å¦‚æœéœ€è¦ç”Ÿæˆç»„åˆçš„CSVæ–‡ä»¶
        if output_format in ['combined', 'both']:
            if all_pairs:
                df_combined = pd.DataFrame(all_pairs)
                # æŒ‰æ—¶é—´æˆ³æ’åº
                df_combined = df_combined.sort_values('timestamp').reset_index(drop=True)
                
                combined_csv_path = self.dataset_path / "dataset.csv"
                df_combined.to_csv(combined_csv_path, index=False)
                generated_files.append(str(combined_csv_path))
                print(f"âœ“ å·²ç”Ÿæˆç»„åˆCSVæ–‡ä»¶: {combined_csv_path}")
            else:
                print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œæ— æ³•ç”Ÿæˆç»„åˆCSVæ–‡ä»¶")
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        self._generate_statistics(all_pairs, valid_cameras)
        
        return generated_files
    
    def _generate_statistics(self, all_pairs: List[Dict], valid_cameras: List[str]):
        """
        ç”Ÿæˆå¹¶ä¿å­˜æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            all_pairs (List[Dict]): æ‰€æœ‰å›¾åƒå¯¹ä¿¡æ¯
            valid_cameras (List[str]): æœ‰æ•ˆçš„ç›¸æœºç±»å‹åˆ—è¡¨
        """
        if not all_pairs:
            return
        
        stats = {
            'dataset_path': str(self.dataset_path),
            'total_image_pairs': len(all_pairs),
            'cameras': {}
        }
        
        # æŒ‰ç›¸æœºç±»å‹ç»Ÿè®¡
        for camera_type in valid_cameras:
            camera_pairs = [p for p in all_pairs if p['camera_type'] == camera_type]
            if camera_pairs:
                timestamps = [p['timestamp'] for p in camera_pairs]
                stats['cameras'][camera_type] = {
                    'count': len(camera_pairs),
                    'earliest_timestamp': min(timestamps),
                    'latest_timestamp': max(timestamps),
                    'duration_seconds': (max(timestamps) - min(timestamps)) / 1e9
                }
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_path = self.dataset_path / "dataset_statistics.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»å›¾åƒå¯¹æ•°: {stats['total_image_pairs']}")
        for camera_type, camera_stats in stats['cameras'].items():
            duration = camera_stats['duration_seconds']
            print(f"{camera_type}: {camera_stats['count']} ç»„ï¼Œ"
                  f"æ—¶é•¿ {duration:.1f}s")
        print(f"âœ“ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_path}")


def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å¤šç›¸æœºæ•°æ®é›†CSVç”Ÿæˆå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ç”Ÿæˆç»„åˆCSVæ–‡ä»¶ï¼ˆé»˜è®¤ï¼‰
  python dataset_generator.py /path/to/dataset
  
  # ä¸ºæ¯ä¸ªç›¸æœºç”Ÿæˆå•ç‹¬çš„CSVæ–‡ä»¶
  python dataset_generator.py /path/to/dataset --format separate
  
  # åŒæ—¶ç”Ÿæˆç»„åˆå’Œå•ç‹¬çš„CSVæ–‡ä»¶
  python dataset_generator.py /path/to/dataset --format both

è¾“å‡ºçš„CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—:
  - camera_type: ç›¸æœºç±»å‹ (camera/camera_femto)
  - timestamp: çº³ç§’çº§æ—¶é—´æˆ³
  - rgb_path: RGBå›¾åƒç›¸å¯¹è·¯å¾„
  - depth_path: æ·±åº¦å›¾åƒç›¸å¯¹è·¯å¾„
  - rgb_camera_info_path: RGBç›¸æœºä¿¡æ¯æ–‡ä»¶ç›¸å¯¹è·¯å¾„
  - depth_camera_info_path: æ·±åº¦ç›¸æœºä¿¡æ¯æ–‡ä»¶ç›¸å¯¹è·¯å¾„
  - rgb_absolute_path: RGBå›¾åƒç»å¯¹è·¯å¾„
  - depth_absolute_path: æ·±åº¦å›¾åƒç»å¯¹è·¯å¾„
  - rgb_camera_info_absolute_path: RGBç›¸æœºä¿¡æ¯æ–‡ä»¶ç»å¯¹è·¯å¾„
  - depth_camera_info_absolute_path: æ·±åº¦ç›¸æœºä¿¡æ¯æ–‡ä»¶ç»å¯¹è·¯å¾„
  - rgb_width: RGBå›¾åƒå®½åº¦
  - rgb_height: RGBå›¾åƒé«˜åº¦
  - depth_width: æ·±åº¦å›¾åƒå®½åº¦
  - depth_height: æ·±åº¦å›¾åƒé«˜åº¦
        """
    )
    
    parser.add_argument(
        'dataset_path',
        help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„'
    )
    
    parser.add_argument(
        '--format', '-f',
        choices=['combined', 'separate', 'both'],
        default='combined',
        help='CSVæ–‡ä»¶è¾“å‡ºæ ¼å¼ (é»˜è®¤: combined)'
    )
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ•°æ®é›†ç”Ÿæˆå™¨
        generator = DatasetGenerator(args.dataset_path)
        
        # ç”ŸæˆCSVæ–‡ä»¶
        generated_files = generator.generate_csv_files(args.format)
        
        if generated_files:
            print(f"\nğŸ‰ æˆåŠŸç”Ÿæˆ {len(generated_files)} ä¸ªCSVæ–‡ä»¶:")
            for file_path in generated_files:
                print(f"  ğŸ“„ {file_path}")
        else:
            print("\nâŒ æœªç”Ÿæˆä»»ä½•CSVæ–‡ä»¶")
            sys.exit(1)
            
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        sys.exit(1)


if __name__ == '__main__':
    main()